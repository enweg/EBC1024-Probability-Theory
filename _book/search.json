[
  {
    "objectID": "01-introduction/01-introduction.html#why-learn-r",
    "href": "01-introduction/01-introduction.html#why-learn-r",
    "title": "Introduction to R",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nIn these notes, we will focus on the R programming language. R is probably the most used programming language in econometric research, and probably the second most used language in data science, data analytics, and related jobs. Thus, learning R does not just allow you to gain a better understanding of what you will learn during this course, but also gives a skill that is directly valued in the industry.\n\nSome of you might wonder why we do not teach Python since it seems to be the most famous programming language. This is simply due to the fact that most research in econometrics and most econometric theory is still first implemented in R. Additionally, R will be your trustworthy companion throughout the rest of your studies. Lastly, we do not teach you R just so that you are able to code in R. Instead, we hope you take away a special kind of thinking that applies to coding in general. Learning how to code is not just about learning the syntax of a programming language; it is about learning how to think in a very specific way. Once you are able to think like a coder, you will quickly be able to learn any programming language, including Python. This kind of thinking will be further strengthened in EBC2016.\n\nAlmost all programming languages, including R, are what is called Turing complete. This means, given enough time and memory, they can solve any computational problem. This also means that there are a lot of things one could do with a programming language, which necessarily comes with a lot of things that one could learn. We will, therefore, not be able to teach you all about coding and R, but instead will focus on what is necessary in probability theory and econometrics in general. We will, therefore, mostly focus on how to do mathematics, how to simulate, and how to communicate results. Later courses in the Econometrics and Operations Research bachelor will teach you some more programming related to data science and operations research, and what you will learn here will hopefully form a good basis for these future courses."
  },
  {
    "objectID": "01-introduction/01-introduction.html#installing-r-and-r-studio",
    "href": "01-introduction/01-introduction.html#installing-r-and-r-studio",
    "title": "Introduction to R",
    "section": "Installing R and R Studio",
    "text": "Installing R and R Studio\n\nMost people use R together with the great development environment R Studio. We therefore recommend that you install both. R can be downloaded from the r-project and we recommend that you follow the instructions for installation given there. R Studio can be downloaded from Posit. Note that the name Posit is relatively new and until recently the company was still called R Studio - so like the development environment itself.\n\nAfter opening R Studio, you should see a window like in Figure 1 except that yours is likely still in light mode. On the left-hand-side is the console, while the two panes on the right-hand-side show you a history of the last commands, and the current environment. The current environment shows you all the variables that are currently available in your environment. This should be empty when you first start R Studio. We will cover in Chapter 3 what variables are and how you can use them. The console, on the other hand, is where we can write commands that are immediately executed after pressing enter. We do not recommend that you work in the console unless you just want to test something. Instead, we recommend you always work in an R-script. You can open a new R-script by pressing File &gt;&gt; New File &gt;&gt; R Script.\n\n\n\n\n\nFigure 1: Screenshot of the R Studio window with the console on the left and the history and environment on the right."
  },
  {
    "objectID": "01-introduction/02-r-calculator.html",
    "href": "01-introduction/02-r-calculator.html",
    "title": "1  R as a calculator",
    "section": "",
    "text": "Note\n\n\n\nWe recommend that you open a new R Script for this section and follow along as you read. Programming is not something that can be learned by just reading about it. You really have to try things and experiment with them. So feel free to change things around and see what happens.\n\n\n\nR is what is called an interpreted programming language. Contrary to compiled programming languages, interpreted programming languages can be used interactively. Thus, upon opening a new R script, and writing something in a line, it can be immediately executed by pressing CMD + ENTER. R can thus be used as a calculator like any other calculator. For example, we can do simple addition by typing the following into a line and executing it.\n\n1 + 1\n\n[1] 2\n\n\nWhat you see in grey above is the code that we are talking about. Here, we asked you to calculate 1+1, which I hope everyone knows is equal to two. This result is given immediately below the code above. The structure above will be generally followed throughout these notes, with a few exceptions. If code would throw an error, meaning that it is broken and something is wrong with it, we will generally not provide any code output. Other exceptions will be made explicitly clear when they occur.\nR can obviously not just do addition. Any operation that you would be able to do on a standard calculator can also be done in R. The code cells below show how subtraction, -, division, /, and multiplication, *, are performed.\n\n11 - 3\n\n[1] 8\n\n\n\n1 / 3\n\n[1] 0.3333333\n\n\n\n55 * 1234\n\n[1] 67870\n\n\n\nThe order in which R executes operations is not always clear. For example, the following became famous online because people either argue that the solution is 1 or that the solution is 16. Technically both is correct since it depends on the precendence of * over / or the other way around, and no unique standard has been formed regarding this precedence. R indeed puts both / and * on the same precendence order but makes clear that in case of two operators within the same precendence order, operations will be performed from left to right. Thus, as is shown below, the result R provides is equal to 16.\n\n8 / 2 * (2 + 2)\n\n[1] 16\n\n\n\nClearly, specifying the order of operations is important, and although R has a standard, it might not be clear to everyone. Thus, it is good practice to explicitly show in which order operations are performed by using parantheses, as shown below. The parentheses below indicate that we want the multiplication to be performed before the division, which results in the second often argued for answer of 1.\n\n8 / (2 * (2 + 2))\n\n[1] 1\n\n\n\nAlthough we will largely focus on scalar operations in the first part of these notes and the course, scalar operations are not ideal for some problems. You should have seen in Linear Algebra, that working with vectors and matrices often comes with advantages. R can be used with matrices and vectors. Indeed, all numerical values are technically vectors in R, even what we would usually call a scalar.\nTo create a matrix in R, we call our first function. The function takes arguments, which are the things that we provide, and returns a result. The function matrix takes as its first argument a list of numbers, c(1, 2, 3, 4). Vectors and lists of numbers always start with c(...) in R. The list of numbers are the numbers of the matrix. Additionally, we need to provide the dimensions of the matrix; two rows and two columns are chosen here. The list of numbers must contain as many numbers as the matrix has entries.\n\n# R is column major and thus fills columns before filling rows\nmatrix(c(1, 2, 3, 4), nrow = 2, ncol = 2)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\n\nThe matrix returned by R has as its first column c(1, 2) and as its second column c(3, 4). This might not be immediately what you expected. Many expect the numbers to be filled row-wise. R uses column-major order though, which means that R stores matrices as a long list of numbers with consecutive numbers corresponding to consecutive entries in a column of the matrix, unless the first number is the last entry in the column, in which case the next number will be the first entry in the next column. In simple terms, this means that R will always fill columns first unless specified otherwise. We can specify that we want the rows to be filled first by adding the additional argument byrow = TRUE.\n\nmatrix(c(1, 2, 3, 4), nrow = 2, ncol = 2, byrow = TRUE)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\n\n\nAs you might have noticed, the first time we created a matrix, we did not specify the argument byrow. Functions often allow user to specify only a few arguments, with the remaining arguments either having default values or being derived using the provided arguments. For example, given the list of numbers has four values, it suffices to provide the nrow = 2 argument, therefore specifying that the resulting matrix must have two rows, which directly implies that the matrix must have two columns.\n\nmatrix(c(1, 2, 3, 4), nrow = 2)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\nTo see which arguments a function takes and which arguments are necessary, you can always consult the help. The easiest way to do so it to type ?function_name into the console, where function_name should be replaced with the actual function name. For example, to get information and help for the matrix function, type\n\n?matrix\n\n\n\n\n\n\n\nUsing Large Language Models\n\n\n\nAssuming that you will not use any Large Language Models (LLMs) would be foolish and forcing you to not use them would mean we stop you from learning a skill that might be invaluable in your future career. We therefore would like to point out that Large Language Models can often help when programming, but their output should not be blindly trusted. For example, in our experience, some of the LLMs will tell you that both the nrow and ncol arguments are necessary. This is clearly not the case. Additionally, while LLMs can be helpful, they can also be a curse. Overly relying on them often implies that you will learn less which eventually implies that you will have trouble in later sections and courses that work on problems that are notoriously difficult for LLMs. In any case, if you do end up using LLMs, always report it and do not just compy the code.\n\n\n\nNow that you know how to create a matrix, we can also perform mathematical operations between matrices and vectors. The first is to use the * operator on two matrices. The * applied to scalars multiplies these scalars. Thus, it is only natural to think that * applied to two matrices will multiply these two matrices. As you see below, this is indeed what is does. However, it does not matrix-multiply the two matrices. Instead, it multiplies them element-wise.\n\nmatrix(c(1, 2, 3, 4), nrow = 2) * matrix(c(1, 2, 3, 4), nrow = 2)\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\n\n\nFor matrix-multiplication, R uses the %*% operator between two matrices, two vectors, or a vector and a matrix. The functionality of %*% exactly follows the rules you learned in Linear Algebra.\n\nmatrix(c(1, 2, 3, 4), nrow = 2) %*% matrix(c(1, 2, 3, 4), nrow = 2)\n\n     [,1] [,2]\n[1,]    7   15\n[2,]   10   22\n\n\n\nmatrix(c(1, 2, 3, 4), nrow = 2) %*% c(5, 6)\n\n     [,1]\n[1,]   23\n[2,]   34\n\n\n\nSometimes we do want to use the element-wise multiplication. In those cases, it is helpful to know how element-wise multiplication works for two arrays (matrices and vectors) that are of different sizes and dimensions. When multiplying a matrix with a vector that has the same length as the total number of elements in the matrix, R will take the vector an element-by-element multiply the element in the matrix with the element in the vector. The order here is again column-major, implying that the first element of the vector is multiplied with the first element in the first column of the matrix, the second element in the vector is multiplied with the second element in the first column of the matrix, and so on.\n\nmatrix(c(1, 2, 3, 4), nrow = 2) * c(1, 2, 3, 4)\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\n\n\nIf the vector has fewer elements than the total number of entries in the matrix, but the total number of elements in the matrix is a multiple of the vector length, then the vector will be recycled. That means, that the multiplication will be performed as above. If the last element of the vector was used, the next entry in the matrix will be multiplied with the first element in the vector again. Thus, R loops through the vector until all entries in the matrix have been multiplied with some element in the vector.\n\nmatrix(c(1, 2, 3, 4), nrow = 2) * c(1, 2)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    4    8\n\n\n\nHowever, if the vector length is not a multiple of the total number of elements in the vector, either a warning is thrown, or the calculation is throwing an error. In general, if a warning as below occurs, something is likely wrong in your code and you should not trust the result unless you double checked that everything is correct.\n\nmatrix(c(1, 2, 3, 4), nrow = 2) * c(1, 2, 3)\n\nWarning in matrix(c(1, 2, 3, 4), nrow = 2) * c(1, 2, 3): longer object length\nis not a multiple of shorter object length\n\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4    4\n\n\n\n\n# This will throw an error.\nmatrix(c(1, 2, 3, 4), nrow = 2) * c(1, 2, 3, 4, 5)\n\n\nAll the rules above for point-wise multiplication also apply to point-wise multiplication from the left.\n\nc(1, 2, 3, 4) * matrix(c(1, 2, 3, 4), nrow = 2)\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\n\n\nc(1, 2) * matrix(c(1, 2, 3, 4), nrow = 2)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    4    8\n\n\nIn more general, they apply to any point-wise multiplication betwen two arrays, no matter their dimension. Thus, when point-wise multiplying two vectors of different lengths, similar rules to the ones above apply.\n\nR also allows for other operations on matrices. For example, a common operation is to take the inverse of a matrix, or to solve a linear system. R provides the solve function for this purpose. Calling solve on a single matrix will return the inverse of the matrix. This is shown below.\n\nm &lt;- matrix(c(1, 3, 2, 4), nrow = 2)\nm_inverse &lt;- solve(m)\nm_inverse %*% m\n\n              [,1]         [,2]\n[1,]  1.000000e+00 4.440892e-16\n[2,] -5.551115e-17 1.000000e+00\n\n\nAs you can see, multiplying the inverse time the original matrix does not provide the exact identity matrix. This is a common problem in computational methods. Computations are only approximately correct. However, the accuracy of common operations in R is sufficient for most work and definitely sufficient for the problems we will be tackling in this course.\nR also provides an alternative way to call solve. Inverse matrices are often taken to solve a system of linear equations. For example, say we would like to solve the system \\(Ax = b\\). The method you have likely learned is to find the inverse of \\(A\\), \\(A^{-1}\\) and to pre-multiply both the left- and right-hand-side by this inverse: \\(A^{-1}Ax = A^{-1}b = x\\). This could be implemented in R, however, a more accurate solution can be obtained by directly solving this linear system. To do so, we call solve with two arguments. The first is the matrix \\(A\\) (the LHS) and the second is the vector \\(b\\) (the RHS).\n\nA &lt;- matrix(c(1, 5, 2, 4), nrow = 2)\nb &lt;- c(1, 1)\nx &lt;- solve(A, b)\nx\n\n[1] -0.3333333  0.6666667\n\n\n\nA_inverse &lt;- solve(A)\nx &lt;- A_inverse %*% b\nx\n\n           [,1]\n[1,] -0.3333333\n[2,]  0.6666667"
  },
  {
    "objectID": "01-introduction/03-variables-indexing.html",
    "href": "01-introduction/03-variables-indexing.html",
    "title": "2  Variables and Indexing",
    "section": "",
    "text": "The first advantage of R over many simple calculators is the ability to save results in variables. Variables are like little boxes in which a slip of paper can be put. The paper might have a word, a sentence, an entire text, a number, or anything else on it. Similarly, a variable can hold a string, which is just text, or a numerical value, or any other objects. Each variable must have a name, which is like a little label on the box that allows us to reuse the variable later on by referring to it. This also implies that each box must have a unique label - each variable must have a unique name.\nInstead of always creating the matrix of the previous section from scratch, we could have also saved it to a variable called A. Object can be saved to variables by using the assignment operator &lt;-. While most programming languages use the = as an assignment operator, there is a slight difference between = and &lt;- in R. So, to be on the safe side, always use &lt;- for assignment to variables.\n\nA &lt;- matrix(c(1, 2, 3, 4), nrow = 2)\nA\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\n\nB &lt;- matrix(c(5, 6, 7, 8, 9, 10), nrow = 2)\nB\n\n     [,1] [,2] [,3]\n[1,]    5    7    9\n[2,]    6    8   10\n\n\n\nAs the two examples above show, the content of variables can be printed to the console by simply calling the variable. However, variables can also be used in calculations by referring to their names. For example, the product of the matrix A and B, which we then save as matrix C, can be obtained in the following way\n\nC &lt;- A %*% B\nC\n\n     [,1] [,2] [,3]\n[1,]   23   31   39\n[2,]   34   46   58\n\n\nSimilarly, any other operations introduced in the previous section can be applied to variables, as long as the variable is holding an appropriate object. So for mathematical operators, the variables must correspond to correct matrices and vectors or scalars.\nWe can double check the above matrix multiplication by manually calculating the first entry of C. From Linear Algebra you should know that\n\\[\nC_{1,1} = A_{1,1}B_{1,1} + A_{1,2}B_{2,1}.\n\\]\nTwo obtain the elements in the matrix, we can index into the matrix. Indexing is performed using square brackets. Since matrices are two dimensional arrays, indexing into matrices requires two numbers. The first number corresponds to the row, and the second to the column. Thus, the calculation above can be performed in the following way:\n\nC11_manual &lt;- A[1, 1] * B[1, 1] + A[1, 2] * B[2, 1]\nC11_manual\n\n[1] 23\n\n\n\nAlthough we said above that indexing into matrices requries two numbers, this is not technically correct if one is not interested in a single element of the matrix. If we are interested in an entire row or column of a matrix, then the column or row element within the square brackets can be left empty.\nFrom linear algebra you should also know that\n\\[\nC_{1,1} = A_{1,\\cdot}B_{\\cdot,2}.\n\\] Thus, we can double check the result in the following way\n\nC11_vector_product &lt;- A[1, ] %*% B[, 1]\nC11_vector_product\n\n     [,1]\n[1,]   23\n\n\n\nIndexing for vectors works similar to indexing matrices with the only difference being that vectors only have a single dimension. To demonstrate this, we first create a vector containing the integers from 1 to 10, which is created using 1:10.\n\nx &lt;- 1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nThe third element of this vector is then equal to 3.\n\nx[3]\n\n[1] 3\n\n\n\nWe can also return a subset of the vector by specifying multiple indices. If the indices of interest are consecutive, we can use : to specify the indices. For example, if we are interested in the first five elements of the vector, we can use 1:5 within square brackets.\n\nx[1:5]\n\n[1] 1 2 3 4 5\n\n\n\nR comes with some handy pre-loaded vectors, including the letters vector, which contains all letters from a to z.\n\nletters\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\n\n\nTo obtain the first, third, fifth, and seventh letter in the alphabet, we can use c(1, 3, 5, 7) within square brackets after letters to index into the first, third, fifth, and seventh element in the vector.\n\nletters[c(1, 3, 5, 7)]\n\n[1] \"a\" \"c\" \"e\" \"g\"\n\n\nIf you carefully followed the above, you should have noticed that we used c(1, 3, 5, 7) to index into the letters vector. Thus, we technically used a vector to index into another vector. This indeed works, as long as the vector used for indexing contains only integers of Booleans. Additionally, the vector used for indexing can only contain elements between 1 and the length of the vector that is being indexed. Since thereSince there are more than ten letters in the alphabet and since x contains all integers from one to ten, we can use x to index into the letters vector.\n\nletters[x]\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\"\n\n\n\nAs pointed out above, we can also use a vector of Booleans to index into a vector. A Boolean is either zero (FALSE) or one (TRUE). Although the vector of Booleans must not technically be of the same length as the vector that is being indexed, we highly recommend to always choose vectors of same length since the results otherwise rely on vector recycling which, as we discussed in the point-wise multiplication case, does not always return what you might expect.\nWhen using a Boolan vector for indexing, a TRUE within the Boolean vector implies, that the corresponding element in the vector that is being indexed, is being returned, while a FALSE implies, that the corresponding entry will not be returned.\n\nx[c(TRUE, TRUE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[1]  1  2  6  7 10\n\n\n\nBoolean indexing combined with conditional statements can often be useful. While we introduce conditionals only later, we will shortly touch on them here to show the power of Boolean indexing.\nThe goal below is to obtain a vector of all even numbers between 1 and 100. To do so, we are using the modulus, %%, operator. The modulus returns the remainder after division. Since all even numbers can be divided by two without a remainder, the modulus of an even number with two will always be zero. On the other hand, an odd number is always one more than an even number and thus, the modulus between an odd number of two will always be one.\n\n10 %% 2\n\n[1] 0\n\n\n\n11 %% 2\n\n[1] 1\n\n\nWe can combine this with the conditional == which returns TRUE if the left-hand-side is the same as the right-hand-side, while it returns FALSE otherwise.\n\n10 %% 2 == 0\n\n[1] TRUE\n\n\n\n11 %% 2 == 0\n\n[1] FALSE\n\n\n\nLike any operator in R, the modulus and the conditional can be applied point-wise to a vector of numbers. Thus, after creating the vector x which contains all numbers from 1 to 100, we can take the modulus of all numbers in x with two and check whether it is zero. We save this result in the new variable x_even_selector. Note, that we tried to give the new variable a descriptive name. In general, this is good practice, and bad variable names usually lead to mistakes later on.\n\nx &lt;- 1:100\nx_even_selector &lt;- x %% 2 == 0\nx_even_selector\n\n  [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [13] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [25] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [37] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [49] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [61] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [73] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [85] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\n [97] FALSE  TRUE FALSE  TRUE\n\n\nThe x_even_selector vector is now a Boolean vector, having a TRUE at entry i if and only if the ith entry of x is even. Thus, we can use the x_even_selector vector to index into x and obtain all even numbers between 1 and 100.\n\nx[x_even_selector]\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nAnother way to obtain all even numbers between 1 and 100 would have been to use the seq function, starting at 2 and incrementing by 2 until 100 is reached.\n\nseq(2, 100, 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100"
  },
  {
    "objectID": "01-introduction/03-02-structures.html",
    "href": "01-introduction/03-02-structures.html",
    "title": "3  Useful Data Structures",
    "section": "",
    "text": "R has many useful data structures. Data structures are, in simple terms, just a collection of data. Different data structures store the data in different ways and, therefore, have different restrictions on what kind of data they can store. Vectors and matrices are two forms of data structures and fall under the broader category of arrays. A vector is nothing else than a one dimensional array, while a matrix is a two dimensional array.\n\nArrays are a rather restrictive data structure, in the sense that R requires each element in an array to be of the same type. A type can be anything like a double (a real number), and integer, a boolean, or a string. Due to the restrictions that arrays impose, a vector storing both an integer and a string is not strictly possible. This, however, does not imply that R will throw an error below. Instead, R uses so-called type-promotion or type-conversion to convert one of the types into another. For example, a number can also be represented as a string (as text), and thus, the below code will convert the 1 to a string.\n\nc(1, \"a\")\n\n[1] \"1\" \"a\"\n\n\n\nLists are a more flexible data structure than arrays. Lists come in two types: unnamed and named. We will first focus on the unnamed versions. A list can be created simply by calling list and providing it with elements.\n\nl &lt;- list(1, 2, 3, 4)\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n[[4]]\n[1] 4\n\n\nCompare the output of the code above to the output you would get for the vector c(1, 2, 3, 4). Clearly, lists and vectors are not the same. Lists are much more flexible than vectors/arrays. You can imagine lists as a collection of boxes, and each element in the comma separated list in parentheses above, gets put into a separate box. A specific box can then be accessed by simply indexing it like the arrays before.\n\nl[1]\n\n[[1]]\n[1] 1\n\n\nLooking at the output, it still looks different to what we have seen before. R provides the handy typeof function to check what type an element has. Calling typeof on the first element in the list shows that the returned element is still a list. Thus, if we index lists like we index vectors or matrices, we get a list back, instead of the element inside the list.\n\ntypeof(l[1])\n\n[1] \"list\"\n\n\nTo obtain the element inside the list, we need to use double square brackets. The returned element is now a double (a real number) as expected.\n\nl[[1]]\n\n[1] 1\n\n\n\ntypeof(l[[1]])\n\n[1] \"double\"\n\n\nOne advantage of lists over arrays is the ability to store different type of data without the types being transformed. Thus, while we could not store a vector c(1, \"a\") without changing the double 1 to a string \"1\", we can store the following list.\n\nl &lt;- list(1, \"a\", TRUE)\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1] TRUE\n\n\nThe reason why lists can store different kind of elements comes back to the analogy above. While arrays are like a single box in which we store all elements, lists are like a collection of boxes. Each box can store just one type of data, but because we can use different boxes, we can store data of different types.\nLists can also be named. We will use this later on to package return values of a function. To name a list, we simply write list(name = element) with name and element being replaced by the actual names and elements. For example, we can store a number, letter, and boolean into a named list in the following way.\n\nl &lt;- list(number = 1, letter = \"a\", boolean = TRUE)\nl\n\n$number\n[1] 1\n\n$letter\n[1] \"a\"\n\n$boolean\n[1] TRUE\n\n\nThis list can still be indexed like an unnamed list, but it can also be indexed using the names. To index a list using its names, we call list$name or list[[\"name\"]].\n\nl[[2]]\n\n[1] \"a\"\n\n\n\nl$letter\n\n[1] \"a\"\n\n\n\nl[[\"boolean\"]]\n\n[1] TRUE\n\n\n\nWhile lists are much more flexible than arrays, they are still not optimal for econometrics. Econometrics is an empirical discipline and thus relies on data. Storing data in the form of lists is possible. However, manipulating the data in lists is tedious. Econometricians, therefore, much more often use so called data frames. Data frames are nothing but a table of data, with each column possibly being of a different data type.\nData frames can be created using data.frame and using a similar syntax to named lists. Different to named lists, the output is much cleaner and the data frame is easier to manipulate.\n\ndf &lt;- data.frame(id = sample(letters, 10), grade = 1:10)\ndf\n\n   id grade\n1   v     1\n2   c     2\n3   d     3\n4   s     4\n5   f     5\n6   u     6\n7   a     7\n8   b     8\n9   o     9\n10  q    10\n\n\nA common data frame you might obtain for your concurrent macroeconomics class contains a column for the year, a column for GDP growth, a column for CPI growth, and a column for unemployment. Such a data frame might thus look like the following.\n\ndf &lt;- data.frame(year = 1960:2024, GDP_growth = rnorm(65, mean=0.5), CPI_growth = rnorm(65), urate = runif(65, min = 3, max = 10))\ndf\n\n   year  GDP_growth   CPI_growth    urate\n1  1960 -1.22243562  0.566773765 6.926558\n2  1961  0.84534647  1.718184714 5.601353\n3  1962  1.96256483  1.518364060 5.171897\n4  1963  0.54319004  2.769155525 4.735195\n5  1964  0.27697046  0.794686166 3.167257\n6  1965  0.56430289 -0.006883313 6.638969\n7  1966  0.65549892  1.194652840 4.020461\n8  1967 -0.67837129 -0.397379433 8.920059\n9  1968 -0.12992637  0.403631193 3.755164\n10 1969  1.72975265  0.331752063 5.853563\n11 1970  0.16167003 -0.810302353 5.745867\n12 1971  1.04712625  0.271369356 3.927922\n13 1972  1.90120993  0.870068010 4.288156\n14 1973  2.60881796  1.173683143 5.979824\n15 1974 -0.11527080  0.743927527 9.531837\n16 1975  1.14465499  0.422704718 8.072365\n17 1976  1.54805795  1.607140240 3.544387\n18 1977  0.30389731  0.124674012 5.479802\n19 1978  2.52482526 -0.041732066 3.244105\n20 1979  0.73430072 -1.761685060 9.820016\n21 1980  0.40084708  0.437343698 6.860646\n22 1981 -0.02462052 -0.281006390 8.704523\n23 1982  0.15006055 -2.627345672 5.618642\n24 1983 -0.35207969 -0.311053466 3.743300\n25 1984  1.46027651 -0.294679660 3.983446\n26 1985 -2.34349005 -0.632824535 5.719955\n27 1986  0.24229163  0.210385281 7.685395\n28 1987  1.26442922 -0.242354885 7.773949\n29 1988 -0.39483103 -1.536032123 4.083268\n30 1989  2.22506820 -0.595155626 4.143458\n31 1990 -0.98125955  0.047043574 5.169099\n32 1991  1.79548949  0.916578077 4.374899\n33 1992  2.70936643  0.994743739 3.184855\n34 1993  0.82728598 -0.856459146 3.851781\n35 1994 -2.08396176 -0.341259805 5.302464\n36 1995  1.24419928  1.505321197 9.609048\n37 1996 -0.05419088  0.432962094 3.835740\n38 1997  1.20454671  0.607197046 3.316178\n39 1998  0.30104796 -0.117635801 6.365440\n40 1999 -0.20482517  0.358752264 3.367027\n41 2000  1.21036478 -0.911980447 9.868248\n42 2001  0.88366877  0.734425593 8.200396\n43 2002 -0.79135566  0.984682192 4.633227\n44 2003  2.40259286  0.095464569 5.604016\n45 2004  0.62896695 -0.258358603 8.671471\n46 2005 -1.10216386 -1.580653487 8.701475\n47 2006 -0.85675981 -0.988274061 7.467863\n48 2007  1.05238415 -0.635749398 3.973571\n49 2008  1.10135485  0.268868883 7.095878\n50 2009  2.70238074 -0.494777111 6.397738\n51 2010 -0.19551987  1.051215885 8.778208\n52 2011 -0.55418837  0.675535844 5.434314\n53 2012  1.04010862 -0.816046548 5.931257\n54 2013  1.12381747  0.760752589 5.218100\n55 2014  1.41320716 -0.923659743 4.265225\n56 2015  0.88946926 -1.162780202 8.688282\n57 2016  1.81570871  0.178834531 7.623710\n58 2017  2.33043864  3.181075195 4.942314\n59 2018  1.50427524  0.109958398 7.561973\n60 2019  1.07238595 -0.798046794 6.779565\n61 2020  0.75324687 -0.836180171 5.149824\n62 2021 -1.31190115  1.777297184 4.073657\n63 2022  0.79141576 -0.156355051 8.594263\n64 2023  0.13686870 -0.308120930 9.796194\n65 2024  1.48017372  0.421053009 7.377092\n\n\nWhile this data frame is technically still considered small, it already becomes clear that the more rows a data frame has, the more difficult it is to get an overview of the data. Having functions that only print some of the rows of the data frame to the console is thus useful. R provides the head and tail functions, with the head function printing the first few rows, and the tail function printing the last few rows.\n\nhead(df)\n\n  year GDP_growth   CPI_growth    urate\n1 1960 -1.2224356  0.566773765 6.926558\n2 1961  0.8453465  1.718184714 5.601353\n3 1962  1.9625648  1.518364060 5.171897\n4 1963  0.5431900  2.769155525 4.735195\n5 1964  0.2769705  0.794686166 3.167257\n6 1965  0.5643029 -0.006883313 6.638969\n\n\n\ntail(df)\n\n   year GDP_growth CPI_growth    urate\n60 2019  1.0723860 -0.7980468 6.779565\n61 2020  0.7532469 -0.8361802 5.149824\n62 2021 -1.3119011  1.7772972 4.073657\n63 2022  0.7914158 -0.1563551 8.594263\n64 2023  0.1368687 -0.3081209 9.796194\n65 2024  1.4801737  0.4210530 7.377092\n\n\nMany more useful functions exist to work with data frames. We recommend you have a small search online. Data frames will be your trustworthy companion throughout the remainder of your studies and over time you will learn many useful manipulation techniques."
  },
  {
    "objectID": "01-introduction/04-clean-code.html",
    "href": "01-introduction/04-clean-code.html",
    "title": "4  Commenting and clean code",
    "section": "",
    "text": "Clean code is important. This is a statement we already made previously but one that we wish to emphasise again. Clean code allows others to easily follow your code and allows yourself to understand your code even after an extended time of not working on it. Clean code is, therefore, the first step in making code and research replicable. The first step towards clean code is to use descriptive variable names. Compare, for example, the two code snippets below. The first one is a copy of a previous one and gives a descriptive name to the selector variable. The second snippet gives the selector the often chosen name temp. Although tempting, temp is not an appropriate name for a variable, which you should see by noticing that the first snippet is much easier to understand than the second snippet.\n\nx &lt;- 1:100\nx_even_selector &lt;- x %% 2 == 0\nx[x_even_selector]\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\n\nx &lt;- 1:100\ntemp &lt;- x %% 2 == 0\nx[temp]\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\n\nDescriptive variable names are only the first step towards clean and understandable code. If variable names cannot reflect sufficient information, then comments should be used. Comments can be added after a code line by separating the comment from the code using two spaces. A comment in R starts with # and everything after # will not be executed - it is simply a short note from the programmer to the reader of the code, which might be the programmer itself.\n\nx &lt;- 1:100\nx_even_selector &lt;- x %% 2 == 0  # Checking if the number is even\nx[x_even_selector]\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nAlthough comments are recommended, it is bad practice to comment each line of code. If you have to comment each line of code, then your code is bad. So technically the comment above is not necessary since the variable name is descriptive enough.\n\nInstead of adding comments after a line of code, comments are much more often added before a line of code. In scripts, these comments often explain what the following lines of code are doing. We generally recommend writing functions, having as little as possible code outside of functions. Functions are covered in a later section.\n\n# Selecting the even integers within the first 100 integers.\nx &lt;- 1:100\nx_even_selector &lt;- x %% 2 == 0\nx[x_even_selector]\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\n\nWhen using comments, think about what is needed to understand the code. If you have some weird calculation going on, explain the calculation. If you have some condional statement that is not immediately clear, explain it. But do not overdo it. Do not write a comment like # dividing by 100. We can see that you are doing it. What we might be interested in is why you are dividing by 100.\n\nAnother helpful strategy to make code cleaner is to split long lines. In general, code lines should not be too long and most programmers will aim to keep code lines less than 80 characters long. The reason for this is that long code lines are often difficult to read and occasionally require a horizontal scroll, which might not be immediately clear to the person that is reading the code. For example, consider a problem in which you need to make the following long calculation.\n\n1 + 123 * 1591 / 1298575 - 124 + 1294 * 19275 / 193587 - 129875 + 19257 * 1957 + 1957135 - 195715 + 195875 / 15975 * 1575 / 1957125 * 135105 + 197515 / 1957135\n\n[1] 39318833\n\n\n\nClearly the long calculation above is difficult to understand. Why are you dividing at one point and multiplying at another? Long calculations such as the ones above are usually a result from merging multiple calculations together. Thus, the first strategy to make it more readable is to split the code over multiple lines as is shown below. This also gives you the ability to comment each line of code and therfore to explain why you divide at one point but multiply at another.\n\n1 + \n  123 * 1591 / 1298575 - \n  124 +  # Each of these lines can contain a comment \n  1294 * 19275 / 193587 - \n  129875 + \n  19257 * 1957 + \n  1957135 - \n  195715 + \n  195875 / 15975 * 1575 / 1957125 * 135105 + \n  197515 / 1957135\n\n[1] 39318833\n\n\n\nAlthough the above is a possible solutions, it is still not clean code. Clean code would instead split the calculation into parts and save each part in a variable with a descriptive name. Yes, we failed to give the variables a descriptive name, but in your calculation, each step should mean something so you should be able to give them descriptive names. The sub-calculations can then be all merged together and saved in a variable holding the final result. Also this variable should have a descriptive name that follows from the calculation you are doing. For example, if you are calculating the expected value of a European option, then the name of the final variable could be european_option_value or simply value if it is clear from the code above that it is the European option value.\n\ncalculation_part1 &lt;- 1 + 123 * 1591 / 1298575 \ncalculation_part2 &lt;- -124 + 1294 * 19275 / 193587 \ncalculation_part3 &lt;- -129875 + 19257 * 1957 + 1957135 \ncalculation_part4 &lt;- -195715 + 195875 / 15975 * 1575 / \n  1957125 * 135105 + 197515 / 1957135\n\nfinal_result &lt;- calculation_part1 +\n  calculation_part2 + \n  calculation_part3 + \n  calculation_part4\nfinal_result\n\n[1] 39318833"
  },
  {
    "objectID": "01-introduction/05-loops.html",
    "href": "01-introduction/05-loops.html",
    "title": "5  Loops",
    "section": "",
    "text": "Loops and conditional statements are what makes programming truly powerful. Loops allow us to repeat something multiple times in a speed that we could never match if we had to do it by hand. Conditional statements, on the other hand, allow us to execute something only if a certain condition holds. Combining these two allows one to do pretty much anything. We will focus on loops first and will cover conditional statements next.\n\nThere are two kinds of loops that are commonly used. The first, the for loop, is used when the number of iterations is known a priori. The second, the while loop, is used if the number of iterations is not a priori known. The for loop is specified using the for command, followed by a statement in parentheses. The statement in parentheses contains the looping variable, here i, and what the looping variable should loop over, here the numbers from 1 to 1000. Thus, the loops is iterating 1000 times. The code that is executed in each iteration of the loop is enclosed in curly brackets. Some people like to start the curly brackets on a new line, while we prefer to start the curly brackets on the same line as the for command. In either case, the closing curly bracket is on a new line following the last command executed in each iteration.\nTo demonstrate the for loop, we use the sequence definition of the Euler number:\n\\[\ne = \\lim_{n\\to\\infty} \\left(1 + \\frac{1}{n}\\right)^n\n\\] Using a for loop, we can obtain the first 1000 elements of this sequence and use them as approximations to \\(e\\).\n\ne_approximation &lt;- c()\nfor (i in 1:1000) {\n  e &lt;- (1 + 1/i)^i\n  e_approximation &lt;- c(e_approximation, e)\n}\ne_approximation[990:1000]\n\n [1] 2.716910 2.716912 2.716913 2.716914 2.716916 2.716917 2.716918 2.716920\n [9] 2.716921 2.716923 2.716924\n\n\nTo check how good these approximations are, and to check how fast the sequence approaches the Euler number, we first need to know what the Euler number actually is. R comes with the \\(exp\\) function which corresponds to \\(e^x\\). Thus, exp(1) is the same as \\(e\\) and equals\n\nexp(1)\n\n[1] 2.718282\n\n\nThe approximation error is then obtained by subtracting \\(e\\), or equivalently exp(1), from each sequency point and taking the absolute value.\n\ne_approximation_error &lt;- abs(e_approximation - exp(1))\n\nTo obtain the first and last ten values of the e_approximation_error vector, we use the head and tail functions respectively, and use the n argument to specify how many values we would like to be returned. As you can see, the last ten values are already correct up to the third decimal.\n\nhead(e_approximation_error, n = 10)\n\n [1] 0.7182818 0.4682818 0.3479115 0.2768756 0.2299618 0.1966555 0.1717821\n [8] 0.1524973 0.1371070 0.1245394\n\n\n\ntail(e_approximation_error, n = 10)\n\n [1] 0.001370217 0.001368837 0.001367460 0.001366085 0.001364714 0.001363345\n [7] 0.001361978 0.001360615 0.001359254 0.001357896\n\n\n\nThe for loop above specified within the statement in parentheses the number of iterations. This is bad practice since the number of iterations is often used in multiple places within the code. It is thus better to specify a variable that holds the number of iterations. A common variable name is N but sometimes a more explicit name is needed if N might be confusing in the context. Using N &lt;- 1e6, we can obtain the first one million elements of the sequence definition of the Euler number. The last ten elements of this sequence are almost equal to the Euler number, at least to a precision that would be enough for most real world applications.\n\nN &lt;- 1e6\ne_approximation_error &lt;- matrix(nrow = N, ncol = 2)\ncolnames(e_approximation_error) &lt;- c(\"i\", \"e_approximation\")\nfor (i in 1:N){\n  e &lt;- (1 + 1/i)^i\n  e_approximation_error[i, ] &lt;- c(i, abs(e - exp(1)))\n}\n\n\nhead(e_approximation_error, n = 10)\n\n       i e_approximation\n [1,]  1       0.7182818\n [2,]  2       0.4682818\n [3,]  3       0.3479115\n [4,]  4       0.2768756\n [5,]  5       0.2299618\n [6,]  6       0.1966555\n [7,]  7       0.1717821\n [8,]  8       0.1524973\n [9,]  9       0.1371070\n[10,] 10       0.1245394\n\n\n\ntail(e_approximation_error, n = 10)\n\n                 i e_approximation\n [999991,]  999991    1.359232e-06\n [999992,]  999992    1.359426e-06\n [999993,]  999993    1.359022e-06\n [999994,]  999994    1.359227e-06\n [999995,]  999995    1.359437e-06\n [999996,]  999996    1.359049e-06\n [999997,]  999997    1.359270e-06\n [999998,]  999998    1.358894e-06\n [999999,]  999999    1.359126e-06\n[1000000,] 1000000    1.359363e-06\n\n\n\nWhat if we do not want to know the approximation error of the first N elements of the sequence, but rather would like to know when the sequency is within a pre-specified distance of the Euler number. In this case, the number of iterations is not a priori known. We therefore need to use a while loop. A while loop executes the code within curly brackets until the statement in parentheses is false. This requires one to update the variables that are used in the statement within parentheses, because otherwise the statement in parentheses will always be true and the while loop will run for ever; a so-called infinite loop. Care must therefore be taken when working with while loops.\nAlthough conditions are only covered in the next section, we use one here. The statement in parentheses reads abs(e - exp(1)) &gt; 1e-4. This statement is true whenever the absolute distance between the variable e and exp(1) is greater than 0.0001. Thus, it is only false when the approximation is correct to the fourth decimal. To make sure that this statement is false at some point, we need to update the variable e within the while loop.\n\ni &lt;- 1\ne &lt;- (1 + 1/i)^i\nwhile (abs(e - exp(1)) &gt; 1e-4) {\n  i &lt;- i + 1\n  e &lt;- (1 + 1/i)^i\n}\ni\n\n[1] 13591\n\n\n\nabs(e - exp(1))\n\n[1] 9.999627e-05\n\n\nSince we defined i and e already outside the while loop, we can also access their values after the while loop has stopped. The sequence is therefore within 1e-4 of the Euler number after element\n\ni\n\n[1] 13591"
  },
  {
    "objectID": "01-introduction/06-conditionals.html",
    "href": "01-introduction/06-conditionals.html",
    "title": "6  Conditionals",
    "section": "",
    "text": "We introduced loops in the previous sections. This section will introduce the other powerful concept in programming: conditionals. Conditionals, as the name hints at, allow to execute code only if a condition is true. For example, if we would like to execute code only when the random \\(\\text{Uniform}(0, 1)\\) variable is less than 0.5, then the code within the conditional will only execute with a probability of 50%. Conditionals therefore allow us to split our code into sections each of which will only be executed if a pre-specified condition is true.\n\nA condition in R connects a left-hand-side with a right-hand-side by using one of the following operators:\n\n==: True if and only if the value on the left-hand-side equals the value on the right-hand-side.\n&gt;: True if and only if the value on the left-hand-side is greater than the value on the right-hand-side.\n&gt;=: True if and only if the value on the left-hand-side is greater or equal to the value on the right-hand-side.\n&lt;: True if and only if the value on the left-hand-side is less than the value on the right-hand-side.\n&lt;=: True if and only if the value on the left-hand-side is less or equal to the value on the right-hand-side.\n!=: True if and only if the value on the left-hand-side is not equal to the value on the right-hand-side.\n!x: True if and only if x is FALSE.\n||: True if and only if either the left-hand-side is true, or the right-hand-side is true, or both are true. Not vectorised.\n|: True if and only if either the left-hand-side is true, or the right-hand-side is true, or both are true. Operates element-wise on arrays.\n&&: True if and only if both the left-hand-side and the right-hand-side are true. Not vectorised.\n&: True if and only if both the value on the left-hand-side and the value on the right-hand-side are true. Operates element-wise on arrays.\n\n\nWhen stating a conditional in natural language, we often use ‘if’ to denote that what we are talking about is a conditional. Similarly, we can use if in R to denote that the code in the following curly brackets should only be executed if the conditional statement within parentheses is true. Take the example below. The conditional in parentheses is testing whether x is less than eleven. Only if this is the case, will we see x &lt; 11 printed out. Test this out by changing x to some other value that violates the condition in parentheses.\n\nx &lt;- 10\nif (x &lt; 11) {\n  print(paste(x, \"&lt; 11\"))\n}\n\n[1] \"10 &lt; 11\"\n\n\n\nWhile if statements are nice, what would we do if we want an ‘else’ or ‘otherwise’? In natural language we often connect ‘if’ with an ‘else’ or ‘otherwise’ to communicate that if the condition is not true, then something else will happen. For example, this years INKOM had options for both rainy and non-rainy days which would be translated as: “If it is raining, we meet in the MAC, else we meet in the park.”. ‘Else’ statements are powerful and thus also a part of programming. Just as an ‘if’ statement can be implemented using if, an ‘else’ can be implemented using else. Extending the example above, we can now also provide some text if x is not less than eleven. Try out what happens when you change x to some other number.\n\nx &lt;- 11\nif (x &lt; 11) {\n  print(paste(x, \"&lt; 11\"))\n} else {\n  print(paste(x, \"&gt;= 11\"))   \n}\n\n[1] \"11 &gt;= 11\"\n\n\n\nAlthough we strongly suggest to stick to if and else, sometimes there is no way around futher complicating the code by using else if. else if is like an additional check. If the first if or a previous else if did not execute, then the condition within the parentheses in the current else if will be checked and the code in curly brackets will be executed if the condition is true.\n\nx &lt;- 13\nif (x &lt; 11) {\n  print(paste(x, \"&lt; 11\"))\n} else if (x == 11) {\n  print(paste(x, \"= 11\"))\n} else {\n  print(paste(x, \"&gt; 11\"))\n}\n\n[1] \"13 &gt; 11\"\n\n\nWe do not recommend the use of else if statements, because they quickly become complex and often better methods exist. Consider the example below. We could have continued in this way for ever, but usually there are better methods to do such comparisons. Throughout these notes, you are likely to find some of these better methods and we will try to point them out when they show up.\n\nx &lt;- 13\nif (x == 1) {\n  print(paste(x, \"= 1\"))\n} else if (x == 2) {\n  print(paste(x, \"= 2\"))\n} else if (x == 3) {\n  print(paste(x, \"= 3\"))\n} else if (x == 4) {\n  print(paste(x, \"= 4\"))\n} else if (x == 5) {\n  print(paste(x, \"= 5\"))\n} else if (x == 6) {\n  print(paste(x, \"= 6\"))\n} else if (x == 7) {\n  print(paste(x, \"= 7\"))\n} else if (x == 8) {\n  print(paste(x, \"= 8\"))\n}\n\n\nWe have already shown in a previous section that Booleans can be used to index into an array. Since conditionals, except && and ||, all operate element-wise, we can also apply a logical operator to a vector which will return a Boolean vector of the same length. So, if we want to filter a vector for values that are less than -0.9, then all we need to do is to write x[x &lt; -0.9]. The condition inside the square brackets will return a Boolean vector that has TRUE at a position if and only if the corresponding element in x is less than -0.9, and thus the indexing will only return such values.\n\n# logical operators work element-wise\nx &lt;- 1:10\nx &gt; 5\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\n\nN &lt;- 1000\nx &lt;- runif(N, min = -1, max = 1)\nx[x &lt; -0.9]\n\n [1] -0.9974925 -0.9792642 -0.9333180 -0.9143725 -0.9927463 -0.9816023\n [7] -0.9904028 -0.9099890 -0.9495764 -0.9357759 -0.9673596 -0.9542919\n[13] -0.9791361 -0.9864559 -0.9185062 -0.9798754 -0.9689796 -0.9667969\n[19] -0.9147646 -0.9760848 -0.9307861 -0.9635357 -0.9021205 -0.9498163\n[25] -0.9234773 -0.9551306 -0.9615087 -0.9451018 -0.9017609 -0.9643029\n[31] -0.9721405 -0.9741869 -0.9617827 -0.9674588 -0.9656485 -0.9319527\n[37] -0.9600621 -0.9342570 -0.9970664 -0.9190525 -0.9619476 -0.9672795\n[43] -0.9633776 -0.9331914 -0.9498500 -0.9752795 -0.9520683 -0.9888410\n[49] -0.9871695 -0.9828671 -0.9922821 -0.9783123\n\n\n\nThe element-wise operation of logical operators can also be used to calculate proportions, probabilities, and counts. For example, we could approximate the probability that x &lt; -0.9 if \\(x \\sim \\text{Uniform}(-1, 1)\\). You will learn throughout the course what this statement means, but the theoretical answer would be \\(0.05\\), so 5%. The simulated answer, using N draws comes close to this, and the larger you choose N, the closer will the simulated answer be to the theoretical answer. The sum in the code below sums up all elements in the vector given to it. Since we are giving it a Boolean vector (because we have a logical operator applied to a vector), we are summing over Booleans. A TRUE is represented by a 1, while a FALSE is represented by a 0. Thus, the sum will return the number of elements in x that are less than -0.9. Dividing by N will then give the proportion which is approximately equal to the theoretical probability.\n\nN &lt;- 1000\nx &lt;- runif(N, min = -1, max = 1)  # drawing N Uniform(-1, 1) numbers\nprobability &lt;- sum(x &lt; -0.9) / N\nprobability\n\n[1] 0.064\n\n\nCare must be taken when applying logical operators to a vector and using the result in an if statement. Since the logical operator works elementwise, the conditional will return a vector. It is then not clear what this should mean for the if statement. Should the if statement be evaluated once per element in the vector? Only if all are true? Only if at least one element is true? Due to this ambiguity, R requires a single Boolean within the parentheses of an if statement. For example, the code below would throw an error. Do you see why?\n\n# Throws the following error: \n# Error in if (x &gt; 5) { : the condition has length &gt; 1\n\nx &lt;- 1:10\nif (x &gt; 5) {\n  print(paste(x, \"&gt; 5\"))\n}\n\nSince R requires a single Boolean within the parentheses of an if statement, we need some way to summarise the information in a vector of Booleans. For example, if we would like to return TRUE if and only if all elements in the Boolean vector are true, then we can use the all function, which takes a Boolean vector and returns TRUE if and only if all elements are TRUE.\n\nx &lt;- 1:10\nall(x &gt; 5)\n\n[1] FALSE\n\n\nSometimes we wish to execute an if statement as long as at least one element in the Boolean vector is TRUE. We can look ahead a bit and use a custom function to return TRUE if and only if at least one element in the Boolean vector is TRUE. We will discuss functions in more detail in the next section. Here, just note, that within the curly brackets after the function statement, it says return(sum(condition) &gt;= 1) so the function returns sum(condition) &gt;= 1 which is TRUE if and only if the sum over all Booleans in the Boolean vector is at least one. Since TRUE==1 and FALSE==0, this is only the case if at least one TRUE is in the Boolean vector.\n\nat_least_one &lt;- function(condition) {\n  return(sum(condition) &gt;= 1)\n}\n\nx &lt;- 1:10\nat_least_one(x &gt; 5)\n\n[1] TRUE\n\n\n\nConditionals become very powerful when they are connected together or negated. In natural language we often use ‘and’, ‘or’, and ‘not’. Similarly, in R we can use && and & for an ‘and’, || and | for an ‘or’, and ! for a ‘not’. The code below showcases each of them. Can you spot why the || will always be true?\n\nx &lt;- 10\nif ((x &lt; 15) && (x &gt; 5)) {\n  print(paste(\"5 &lt;\", x, \"&lt; 15\"))\n}\n\n[1] \"5 &lt; 10 &lt; 15\"\n\n\n\nx &lt;- 10\nif ((x &gt; 5) || (x &lt; 15)) {\n  print(\"I am always true, why?\")\n}\n\n[1] \"I am always true, why?\"\n\n\n\nx &lt;- 10\nif (!(x &gt; 5)) { \n  print(paste(x, \"&lt;= 5\"))\n}"
  },
  {
    "objectID": "01-introduction/07-functions.html",
    "href": "01-introduction/07-functions.html",
    "title": "7  Functions",
    "section": "",
    "text": "Functions are used a lot in programming. They can be imagined like small machines that take an input, work on it, and provide an output. This behaviour makes them ideal for complex projects, but we highly recommend using them for smaller projects too. Until this point, we have not used functions and thus everytime we wanted to re-do a certain operation, we had to write the entire code again. Functions mitigate this problem by providing a re-usable machine.\n\nThe syntax for a custom function looks at first like a variable assignment, with the variable name on the left-hand-side, followed by the assignment operator &lt;-. However, contrary to a standard variable assignment, a function operator follows the assingment operator. Following in parentheses after the function operator are the function arguments. These are the inputs to the little machines. In the at_least_one function, the only argument is the condition. The functionality of the function is then inside curly braces with the last line being a return statement. Although some functions do not return anything, most functions do. In the case of the at_least_one function, a Boolean is returned that is TRUE if and only if at least one element in the condition vector is TRUE. A custom function can then be called like any build-in function or method.\n\nat_least_one &lt;- function(condition) {\n  return(sum(condition) &gt;= 1)\n}\nat_least_one(1:10 &lt; 3)\n\n[1] TRUE\n\n\n\nThe advantage of functions is their reusability and the focus of doing just one thing. The focus of doing just one thing is enforced by the developer and is often the most difficult part. The reusablity comes almost at no cost, but must be planned in. For example, below we provide a function that samples from a half Normal distribution which is truncated below at zero. While this function is re-usable in the sense that we can sample from a half Normal truncated below at zero by just calling the function, it could have been more reusable by letting the user choose the upper and lower truncation points.\nTo sample from the half-normal distribution, we specify a single argument, n, corresponding to the desired number of samples. The actual sampling procedure then works by repeatedly drawing from a standard Normal distribution. If the drawn number is greater than zero, it is kept. On the other hand, if the value is less than zero, it is rejected and another draw is taken. This is not the most efficient algorithm, but the simplest one to implement. Note that we do not know the number of draws from the standard Normal distribution, since we could be unlucky and draw negative values for a very long time. Thus, we use a while loop which tests every time whether the previously drawn value is less than zero. If it is, it will draw another value, otherwise it will stop. Lastly, note that we have pre-specified the draws vector and initialised its values using NA. NA is a place holder that indicates missing values. We pre-specified the draws vector because it makes the algorithm faster than having to extend a vector everytime a draw is accepted. We recommend to always pre-specify matrices and vectors.\n\ndraw_half_normal &lt;- function(n) {\n  draws &lt;- rep(NA, n)\n  for (i in 1:n) {\n    r &lt;- rnorm(1)\n    while (r &lt; 0) {\n      r &lt;- rnorm(1)\n    }\n    draws[i] &lt;- r\n  }\n  return(draws)\n}\n\n\nThe draw_half_normal function can then be called as below, where we obtain 100 draws from a standard Normal truncated below at zero. The advantage of a function, as previously pointed out, is their re-usability. To obtain more draws, all you need to do is to change the argument to the function; try this! Additionally, if we wanted to have two vectors of draws from the half Normal distribution, we could simply call the function twice and save the result in a new variable each time.\n\ndraw_half_normal(100)\n\n  [1] 0.45709290 0.65401037 0.43586281 1.19853499 0.59987462 1.14481720\n  [7] 2.22447493 1.68943950 0.43794657 1.71054881 0.50979344 0.80914342\n [13] 0.71718882 0.99275021 0.81868894 0.86998941 0.46343642 0.18422237\n [19] 0.70153899 0.24977918 0.81834360 0.36471829 0.27479870 1.96775751\n [25] 0.23167235 2.06276381 0.94385340 2.40986227 0.42479999 1.25787305\n [31] 1.11800680 1.00619394 0.05183374 0.18959480 1.17541298 0.07877704\n [37] 0.80124483 0.90916568 0.53407596 0.18316350 0.46820126 0.39548699\n [43] 0.16075491 0.97598194 1.27159873 2.18056470 0.05182188 0.92383544\n [49] 1.68749935 0.28460472 0.13030966 0.51953610 0.66847058 0.41456854\n [55] 0.94537431 1.75264400 1.01593991 0.24067977 0.94091599 0.87956309\n [61] 1.33517174 0.49361599 0.98983602 0.05129748 0.84289246 0.11242971\n [67] 0.79826418 0.13456220 0.10484607 2.24501043 2.02206959 0.39319482\n [73] 0.89447931 1.24714418 0.77107770 0.37771452 0.04042705 1.69647114\n [79] 1.07966189 1.09681948 0.12812136 2.08408279 0.38104838 0.83887578\n [85] 0.79207953 0.55743382 1.10409377 1.13329611 0.72022935 0.07624614\n [91] 0.26004353 0.52390156 0.02187510 1.67897773 0.39069874 0.94950866\n [97] 0.81963443 0.02462473 1.01198243 0.91446166\n\n\n\nYou might wonder why we teach you to code in a probability theory class. The answer is simply that we believe that programming helps to gain intuition and helps to check your answers. More advanced students and researchers do this regularly. They often start of by first using code to experiment around, then use the intuition and insights gained from there to obtain theoretical results, which can then be compared to simulated results. If both theoretical and simulated results agree, then the theoretical result is likely correct. However, if the theoretical and simulated result disagree, then the researcher or student has to investigate whether the theoretical result or the simulated result is wrong.\nAn example of how to use this procedure is depicted below. We developed a simple way to draw from a Normal distribution that is truncated below at zero and implemented it in the draw_half_normal function. Naturally, there also exist theoretical results for the probability density distribution of such a truncated Normal distribution and the theory we will cover during this course will allow you to derive this theoretical form. Once the theoretical result has been derived, it can be compared to the simulated result by simulating many, here 1000, draws and plotting the density histogram, which can then be compared to the theoretical probability density. The histogram is represented by the grey bars, while the theoretical density is plotted in red. In our case, these are very similar, reassuring us that both the theoretical and simulated results are correct.\n\ndraws &lt;- draw_half_normal(10000)\nx &lt;- seq(min(draws), max(draws), 0.01)\nhist(draws, \n     breaks = 50, \n     freq = FALSE, \n     xlab = \"\", \n     main = \"Draws of a half-Normal(0,1)\")\nlines(x, 2*(1/sqrt(2*pi))*exp(-0.5*x^2), col=\"red\")\n\n\n\n\nThe previous example has shown that we can use functions to implement our own sampling procedure and compare the samples obtained from it with theoretical densities. Another common use of functions in probability theory is to simulate a single path of a stochastic process. Don’t worry about what a stochastic process is. For now imagine it as a sequence of random events that could possibly be dependent. A common example of a stochastic process is a random walk. A random walk usually has the following setup: Imagine a drunk person that is currently somewhere between the bar and their home. At each time point, the drunken person makes either a step forward or a step backward each with equal probability. A question we might be intersted in is the probability that the drunken person will reach their home in less than \\(100\\) steps. We might also be interested in the probability that the drunken person ends up back at the bar before they reach their home. In either case, we could either calculate the probability using theory, or we can simulate the random walk multiple times. We will postpone the answer to these questions to a later section. Instead, we focus for now on the implementation of a function that simulates a single random walk.\nThe function below simulates a simple random walk. Just as any function, it starts with a function keyword followed by arguments in the parentheses. Different to previous functions you have seen, some of the arguments have default values. For example, start = 0 and step_size = 1. Default values should only be used if sensible defaults exist. If an argument has a default value, the argument must not be provided by the user. But, if the user provides a value for it, the default value will be overwritten. The actual implementation of the random walk is then relatively straight forward. We first initialise the current_position to be the start position. We also initialise a positions vectors which will store all the positions that were visited. Since we do not know the number of steps needed until the drunken person arrives either at home or back in the bar, we cannot give the vector a default length. Since we do not know the number of steps, we can also not use a for loop. Instead, we need to use a while loop. We also want the while loop to stop whenever the drunken person either arrived at home, which would mean that their position is greater or equal than stop_upper, or the person arrived back in the bar, which would mean that their position is less or equal than stop_lower. We thus run the while loop as long as the position is within stop_upper and stop_lower. In each iteration of the while loop, we first sample the direction of the step using sample(c(-1, 1), 1) which randomly returns either -1 or 1 with equal probability. The new current_position is then the old current_position plus the direction times the step size. The final two steps in the loop are saving the new position to the positions vector, and increasing the number of steps taken. Lastly, all functions you have seen so far had only a single return value. Sometimes we want to return more than one value. For example, here we would like to to return both the number of steps taken and the actual path taken. This can be achieved by using a list which, as shown below, can have named entries.\n\nsimulate_random_walk &lt;- function(stop_lower, stop_upper, start = 0, step_size = 1) {\n  current_position &lt;- start\n  positions &lt;- c(current_position)\n  steps_taken &lt;- 0\n  while ((current_position &gt; stop_lower) && (current_position &lt; stop_upper)) {\n    step_direction &lt;- sample(c(-1, 1), 1)\n    current_position &lt;- current_position + step_direction*step_size\n    positions &lt;- c(positions, current_position)\n    steps_taken &lt;- steps_taken + 1\n  }\n  return(list(\n    steps_taken = steps_taken, \n    path = positions\n  ))\n}\n\n\nThe function we have just implemented can then be called like any other functions we developed before with the exception that default arguments can be left out when calling the function. To provide new values for the defaults, the arguments need to be specified by name: they are keyword arguments. The order in which they appear does not matter as long as you specify the name. This is in general true. Even for arguments that do not have default values, the order can be switched around if they are explicitly referred to by name. Below are three ways in which we could call the function. Note that the output is different each time since we work with random numbers. We will cover randomness in more detail in the next section. There we also cover how to make sure that the output is the same whenever we would want it to be the same.\n\nsimulate_random_walk(-20, 10, start = 0, step_size = 1)\n\n$steps_taken\n[1] 76\n\n$path\n [1]  0  1  2  3  2  1  2  3  2  1  0  1  0  1  0  1  0 -1  0  1  2  1  2  3  2\n[26]  3  4  3  2  3  2  1  0 -1 -2 -3 -2 -1  0  1  0 -1  0 -1  0 -1  0  1  2  3\n[51]  4  5  6  7  8  9  8  7  6  7  6  5  6  5  6  5  6  5  6  7  8  7  6  7  8\n[76]  9 10\n\n\n\nsimulate_random_walk(-20, 10)\n\n$steps_taken\n[1] 124\n\n$path\n  [1]   0  -1  -2  -1  -2  -1   0   1   0  -1  -2  -3  -4  -3  -4  -3  -2  -3\n [19]  -4  -5  -6  -7  -8  -9 -10  -9  -8  -7  -6  -5  -4  -5  -6  -5  -6  -7\n [37]  -8  -9  -8  -9  -8  -7  -8  -7  -8  -7  -6  -7  -8  -7  -6  -5  -4  -3\n [55]  -2  -3  -4  -3  -4  -5  -4  -5  -4  -5  -4  -5  -4  -5  -6  -5  -6  -7\n [73]  -8  -9  -8  -9  -8  -7  -6  -5  -6  -7  -8  -7  -6  -5  -6  -7  -6  -5\n [91]  -6  -5  -4  -5  -6  -5  -4  -3  -4  -3  -2  -1   0  -1   0   1   0   1\n[109]   2   3   4   5   6   7   8   7   6   5   4   5   6   7   8   9  10\n\n\n\nsimulate_random_walk(stop_upper = 10, stop_lower = -20)\n\n$steps_taken\n[1] 234\n\n$path\n  [1]  0  1  2  1  2  3  2  1  2  1  0 -1 -2 -1  0 -1  0 -1 -2 -1 -2 -1 -2 -1  0\n [26] -1 -2 -3 -4 -5 -4 -5 -4 -3 -2 -3 -2 -3 -2 -1  0 -1  0  1  0 -1 -2 -1 -2 -1\n [51]  0  1  0 -1  0 -1 -2 -1 -2 -1  0  1  0 -1 -2 -3 -2 -3 -4 -5 -6 -5 -6 -7 -6\n [76] -5 -4 -3 -2 -3 -2 -3 -2 -3 -4 -5 -4 -3 -2 -1 -2 -3 -4 -3 -2 -1 -2 -1  0 -1\n[101] -2 -1  0  1  2  1  0 -1 -2 -3 -4 -5 -4 -5 -6 -5 -4 -3 -4 -5 -4 -3 -4 -3 -2\n[126] -3 -2 -3 -2 -3 -4 -5 -4 -3 -2 -1  0 -1  0 -1  0  1  2  1  2  1  2  3  2  1\n[151]  0  1  0 -1 -2 -1 -2 -3 -2 -1  0  1  2  3  4  3  2  3  2  3  4  3  4  3  2\n[176]  1  2  3  2  3  4  3  2  1  2  3  4  5  4  3  2  1  2  1  2  3  2  1  2  1\n[201]  0  1  2  1  2  1  2  3  2  3  4  3  4  5  4  3  4  5  6  7  6  5  6  5  6\n[226]  5  6  5  6  7  8  9  8  9 10\n\n\n\nThe function simulate_random_walk returns a list. The above output shows how this looks like. A list will generally be printed to the console by first writing the name of the element like $steps_taken followed on the next line by the actual content of that element. If we instead save the output of the function to a variable, that variable will also be a list. To get the named elements, we can simply put a $ after the variable name and speicify which element in the list we would like. This is shown below. Note that this only works for named lists.\n\nrandom_walk &lt;- simulate_random_walk(-20, 10)\nrandom_walk$steps_taken\n\n[1] 388\n\n\n\nWe have already used visuals above to understand what was going on and to check whether our simulations agree with our theoretical results. Visualisations will follow us throughout the course, and your entire career simply because they are one of the most natural ways of communicating results. For example, instead of looking at the endless long vector of positions in the console, we can simply plot the path, which is more intuitive to understand. We do this below by first obtaining the path from the named list and then plotting the path.\nThe first argument to plot are the x-cooredinates. Since these are simply the step numbers, we can simply provide a vector of integers from 1 to the number of steps taken, which we obtain using length(random_walk_path). The second argument to plot are the y-coordinates, which are the actual positions. Following this are some additional arguments. Check out the help using ?plot and see if you can figure out what they do. The two ablines are used to plot the home and bar positions respectively.\n\nrandom_walk_path &lt;- random_walk$path\nplot(1:length(random_walk_path), \n     random_walk_path, \n     type = \"l\", \n     main = \"Path of a Random Walk\", \n     xlab = \"Step\", \n     ylab = \"Position\", \n     ylim = c(11, -21)\n     )\nabline(h = 10, col=\"red\")\nabline(h = -20, col=\"red\")\n\n\n\n\n\nStochastic processes are sequences of potentially dependent random events. These generally happen over time and thus the data obtained from stochastic processes are usually referred to as time series. A common question when working with time series is what the mean of the series was over, say, the last ten time steps. More generally, one would like to know this for each point in time. Thus, we would like to know what the moving mean was, or sometimes referred to as a the window mean. For each time point in the time series we calculate the mean of the last ten days including the current day and save the value. We then move one time point forward and do exactly the same. We do this until the end of the time series. Depending on the window size, the resulting time series, which is itself a stochastic process, will look like a smooth version of the original time series. The window mean is implemented below. Can you explain what each part of the code does?\n\nwindow_mean &lt;- function(x, window_length, na.rm = FALSE) {\n  N &lt;- length(x)\n  number_windows &lt;- N - window_length + 1\n  window_means &lt;- rep(NA, number_windows)\n  for (i in 1:number_windows) {\n    window_means[i] &lt;- mean(x[i:(i+window_length-1)], na.rm = na.rm)\n  }\n  return(window_means)\n}\n\n\nAlthough we have thus far not done so, every implemented function should be tested. This is usually referred to as unit testing and we recommend that you look it up and use it more and more. For now, we will use simple checks for our window_mean function. First, if the window_size == length(x), then the mean is taken over all entries in the vector which we could equivalently achieve by using the mean function. These two, therefore, should be the same, and as is shown below are the same. Second, We can check the calculation of the first window result. If we choose the window_size=5, then the first element of the returned vector should be the same as mean(x[1:5]). As you can see below, this is the case. These tests give us confidence that our function is correctly implemented. More tests would give us even more confidence.\n\nx &lt;- 1:10\nwindow_mean(x, 10) == mean(x)\n\n[1] TRUE\n\n\n\nwindow_mean(x, 5)[1] == mean(x[1:5])\n\n[1] TRUE\n\n\n\nAs already mentioned above, running a mean over a moving window to a certain extend smoothes a time series. This is shown in the figure below where the solid line is the moving mean, the dashed line is the random walk, and the upper and lower red horizontals are the home and bar position respectively. Clearly, the smoothed series follows the original series with a delay, but has fewer spikes.\n\nwindow_size &lt;- 10\nrandom_walk_path_smooth &lt;- window_mean(random_walk_path, window_size)\nplot(window_size:(length(random_walk_path_smooth) + window_size - 1), \n     random_walk_path_smooth, \n     type = \"l\", \n     main = \"Path of a Random Walk - Smoothing using MA(10)\", \n     xlab = \"Step\", \n     ylab = \"Position\", \n     ylim = c(11, -21)\n     )\nlines(1:length(random_walk_path), random_walk_path, col = \"black\", lty = 2)\nabline(h = 10, col=\"red\")\nabline(h = -20, col=\"red\")\n\n\n\n\n\nNex to a mean applied over a moving window, we might also be interested in the sum over a moving window. For example, if we had a poisson process, we might be interested in the total number of occurances within the last ten periods. The function below implements this. Can you explain what each part is doing? If you compare this function to the window_mean function, do you notice something?\n\nwindow_sum &lt;- function(x, window_length, na.rm = FALSE) {\n  N &lt;- length(x)\n  number_windows &lt;- N - window_length + 1\n  window_sums &lt;- rep(NA, number_windows)\n  for (i in 1:number_windows) {\n    window_sums[i] &lt;- sum(x[i:(i+window_length-1)], na.rm = na.rm)\n  }\n  return(window_sums)\n}\n\n\nx &lt;- 1:10\nwindow_sum(x, 10)\n\n[1] 55\n\n\n\nwindow_sum(x, 5)\n\n[1] 15 20 25 30 35 40\n\n\n\nYou should have noticed that the window_mean and window_sum functions have a large code overlap. Indeed, to code the window_sum function, we basically just copied the window_mean function and made small changes. This is one of the biggest mistakes you could do in programming. Never copy code. If you need similar code at various places in your program, think whether you could make a function out of the code. This function can then be used at the various places. The advantage of this is that if there is a mistake in the code, you can easily fix it. Additionally, if code needs to be copied, it likely represents a set of operations with a single goal. Thus, it is perfect for a function that can then be tested using unit tests or simple tests, as we have shown above.\nThe window_apply function below takes this step. It takes all the shared lines of code from window_mean and window_sum and makes a separate function out of it. Instead of applying a specific function over a window, it instead takes a function f as argument, which is then applied to each window. The ... at the end of the argument list is a place holder for any other arguments the user might want to provide. These are then forwarded to the function, f, by putting ... at the end of the function call. The window_apply function thus shows that functions can be arguments to functions. This is a powerful concept and you will encounter it multiple times.\n\nwindow_apply &lt;- function(x, f, window_length, ...) {\n  N &lt;- length(x)\n  number_windows &lt;- N - window_length + 1\n  window_results &lt;- rep(NA, number_windows)\n  for (i in 1:number_windows) {\n    window_results[i] &lt;- f(x[i:(i+window_length-1)], ...)\n  }\n  return(window_results)\n}\n\n\nwindow_apply(1:10, sum, 5, na.rm = FALSE)\n\n[1] 15 20 25 30 35 40\n\n\n\nUsing the general window_apply function, we can then implement the window_sum_better and window_mean_better function which share much less code. These functions are technically just convenience functions, since a user could also call window_apply, but sometimes it is nice to have such convenience functions, especially because they explicitly state what they are doing. Not surprisingly, the window_sum_better and window_sum functions return the same values, and so do the window_mean_better and window_mean functions.\n\nwindow_sum_better &lt;- function(x, window_length, na.rm = FALSE) {\n  results &lt;- window_apply(x, sum, window_length, na.rm = na.rm)\n  return(results)\n}\nwindow_mean_better &lt;- function(x, window_length, na.rm = FALSE) {\n  results &lt;- window_apply(x, mean, window_length, na.rm = na.rm)\n  return(results)\n}\n\n\nx &lt;- 1:10\nall(window_sum_better(x, 5) == window_sum(x, 5))\n\n[1] TRUE\n\n\n\nx &lt;- 1:10\nall(window_mean_better(x, 3) == window_mean(x, 3))\n\n[1] TRUE\n\n\n\nWhile other languages have types which specify what the input arguments to a function are (at last type wise), R does not have such types and thus we could technically input anything to a function. For example, we could call the window_apply function but instead of a function could provide a string.\n\n# The following line will throw the error: \n# Error in f(x[i:(i + window_length - 1)], ...) : \n# could not find function \"f\"\nwindow_apply(1:10, \"hello\", 10)\n\nWhy would anyone provide a string instead of a function? Because we have not yet properly documented what the argument should be. There are technically two ways to prevent such mis-behaviour. The first is to have checks at the beginning of a function to test whether all arguments are what we would expect. While this is good, we will instead focus on appropriate documentation and will trust that the user is capable of following instructions given in the documentation. We highly recommend using Roxygen function documentations. Roxygen function documentation puts comments right above a function definition. Different to normal comments, Roxygen comments start with #'. The first of such comments is a title or description of the function. Following this, and after a blank line, are some more details about the function. These details could, for example, explain the theoretical model that is being simulated. After the details and a blank line are @param statements which define the meaning of the parameters/arguments of the function. The @return specifies the return value of the function, and the lines after the @examples provide examples of how to use the function. We recommend that every time you write a function you follow this documentation scheme and explicitly document what the function does. This way we, you, and others reading your code will better understand what is going on and will potentially be able to re-use the code for other projects.\n\n#' Apply a function over a moving window\n#' \n#' The function `f` is applied to `x` over a moving window of size\n#' `window_length` with the window moving forward one step in each\n#' iteration. \n#' \n#' @param x A vector.\n#' @param f A function that can be applied to a subvector of `x`.\n#' @param window_length The length of the window over which the\n#' function is applied.\n#' @param ... Additional arguments passed on to `f`.\n#' @returns A vector containing the evaluated function calls.\n#' @examples\n#' window_apply(1:10, mean, 5, na.rm = TRUE)\n#' window_apply(1:10, sum, 5, na.rm = TRUE)\nwindow_apply &lt;- function(x, f, window_length, ...) {\n  N &lt;- length(x)\n  number_windows &lt;- N - window_length + 1\n  window_results &lt;- rep(NA, number_windows)\n  for (i in 1:number_windows) {\n    window_results[i] &lt;- f(x[i:(i+window_length-1)], ...)\n  }\n  return(window_results)\n}"
  },
  {
    "objectID": "01-introduction/08-random-numbers.html",
    "href": "01-introduction/08-random-numbers.html",
    "title": "8  Random numbers",
    "section": "",
    "text": "Random numbers and random variables play an important role in probability theory. So do distributions of these random variables. While you will later learn what random variables and distributions are, we will here introduce the basics of them in R.\nImagine rolling two dice and summing the outcome of the two. The value you obtain is a random number and if we assign it a meaning, it is a random variable. Why is it random? Simply because the outcome of each die was random. If you repeat the experiment you are likely to get new values. Now, computers cannot role die for us and thus they cannot generate truly random numbers. However, what they are incredible good at is to simulate values that are as good as random for any practical purposes. How they do this is beyond the scope of these notes, but feel free to look it up online.\nAn example of a random number is a value between zero and one with each value being equally likely to appear. We call this a \\(Uniform(0,1)\\) distribution and we can obtain a value from this distribution by running\n\nrunif(1)\n\n[1] 0.5952391\n\n\nEach time you run the above line you will get a different value and you will not be able to predict the next value no matter how many of the previous values you saved and what algorithm you are using. This is why we call these numbers random in any practical sense.\nThe Uniform distribution can also be extended to larger and smaller values. For example, we might want to obtain a random value between -10 and 10 with all values being equally likely. This is an example of a Uniform(-10, 10) distribution, and similar to above, we can obtain a draw from this distribution by simply providing the min and max values of the Uniform distribution.\n\nrunif(1, min = -10, max = 10)\n\n[1] 8.383511\n\n\nWhat if we need more than one value? R makes this rather simple and usually the first argument to any distribution is the number of draws you want from that distribution. So instead of choosing 1 as in the code above, we could also choose 10 to obtain ten values of the same distribution. Since all values are equally likely, there is a zero probability that any of the ten values will be the same. Do not worry if this does not yet make sense. At the end of the course you will understand why. And if you do not trust us, feel free to sample one million values and check if any of them are the same.\n\nrunif(10, min = -10, max = 10)\n\n [1]  5.87106044  1.11729069 -2.08704065  5.91118969  1.30680212  8.51654049\n [7] -5.73460022  9.58005074 -0.01469716 -7.40182493\n\n\nThe ability to sample multiple values from the same distribution also allows us to obtain a random matrix for which each element is drawn independently from the same distribution. Independence means that knowing the value of one entry in the matrix will tell you nothing about what the other values will be. We will formalise this definition later on. To sample a random matrix with each element coming from the same distribution, we simply sample eneough draws from the distribution and reshape it into a matrix.\n\nmatrix(runif(10*5, min = -10, max = 10), nrow = 10)\n\n            [,1]       [,2]      [,3]       [,4]      [,5]\n [1,] -8.0611143 -7.5952552  8.787650  6.8079214  1.543419\n [2,] -0.7550393 -1.7846112 -8.533333  2.6134487  7.300039\n [3,] -9.0101318 -7.9999971 -5.444208 -6.4569593  8.639243\n [4,] -9.3002559  6.9252351  5.864120  4.0568605  8.578383\n [5,]  9.1148238  9.0315916  7.531192 -7.4674050  9.904430\n [6,]  1.1021637  7.8038948  5.812212 -7.6899286 -6.504226\n [7,]  7.6106918  0.8792745 -7.395454 -2.8241966 -5.380932\n [8,]  9.1925075  3.8648222 -6.851586 -9.0190301 -4.839566\n [9,]  9.5841651  3.6428482 -5.236099 -0.1349847 -3.722839\n[10,]  8.3010488  3.4252708  0.333706  9.2855373  2.832927\n\n\nWhat if we wanted to draw from another distribution? Many commonly used distributions exist and you will encounter many of them during this course. R implements most of them, with Table 8.1 providing an overview of the functions used for each distribution. Thus far we have only used the r* function and we will show the use of a d* functions below. We will encounter the other functions throughout the remainder of this course.\n\n\nTable 8.1: Collection of common distributions and their corresponding functions in R.\n\n\n\n\n\n\n\n\n\nDistribution\nPDF/PMF\nCDF\nQuantile Function\nRandom Variate\n\n\n\n\nBeta\ndbeta\npbeta\nqbeta\nrbeta\n\n\nBinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\nCauchy\ndcauchy\npcauchy\nqcauchy\nrcauchy\n\n\nChi-Squared\ndchisq\npchisq\nqchisq\nrchisq\n\n\nExponential\ndexp\npexp\nqexp\nrexp\n\n\nF\ndf\npf\nqf\nrf\n\n\nGamma\ndgamma\npgamma\nqgamma\nrgamma\n\n\nGeometric\ndgeom\npgeom\nqgeom\nrgeom\n\n\nHypergeometric\ndhyper\nphyper\nqhyper\nrhyper\n\n\nlog-Normal\ndlnorm\nplnorm\nqlnorm\nrlnorm\n\n\nMultinomial\ndmultinom\npmultinom\nqmultinom\nrmultinom\n\n\nNegative Binomial\ndnbinom\npnbinom\nqnbinom\nrnbinom\n\n\nNormal\ndnorm\npnorm\nqnorm\nrnorm\n\n\nPoisson\ndpois\nppois\nqpois\nrpois\n\n\nStudent’s t\ndt\npt\nqt\nrt\n\n\nUniform (Cont.)\ndunif\npunif\nqunif\nrunif\n\n\nWeibull\ndweibull\npweibull\nqweibull\nrweibull\n\n\n\n\nAccording to Table 8.1, to draw from the Normal/Gaussian distribution, we should use rnorm. The Normal distribution does not have the same arguments as the Uniform distribution though. Thus, even though we can just call rnorm(1), we will not get a value between 0 and 1 as in the runif(1) case. Instead, the value could theoretically be anything, with the value most likely being somewhere between -1.96 and 1.96.\n\nrnorm(1)\n\n[1] -1.243489\n\nrnorm(1, mean = 10, sd = 4)\n\n[1] 7.637215\n\nrnorm(10, mean = 10, sd = 4)\n\n [1]  9.812741 14.759151 10.537713 17.347994  7.892119  6.615749  8.828709\n [8]  5.882811 11.818310 11.353453\n\nmatrix(rnorm(10*5, mean = 10, sd = 4), nrow = 10)\n\n           [,1]      [,2]      [,3]      [,4]      [,5]\n [1,] 14.711556  8.776794  9.025872 15.579753 11.439231\n [2,]  6.729269  7.387324  6.379581 12.314222 11.889575\n [3,]  6.970163  4.776292  6.635297 13.207341  7.366270\n [4,] 11.333158 14.572759  7.232898 17.734295 14.469193\n [5,] 14.801428 16.035830 14.960768  9.799239  6.844820\n [6,]  7.277084  9.291320  5.164475 11.782791 17.212235\n [7,]  8.182604  8.527448 10.272915  7.817562 16.071967\n [8,] 10.734756 15.057814 16.804846  8.483281  8.811159\n [9,] 15.560284 11.038507  7.707942 15.353353  6.829901\n[10,] 12.431203 10.124763  7.750745  5.363917  7.441523\n\n\nWhile the Uniform distribution is parameterised by the minimum and maximum values, the Normal distribution is parameterised by the mean and standard deviation. Both are already used above to obtain different random values from the Normal distribution, but if you want to know more about this parameterisation and the Normal distribution, you can always ask the help.\n\n?rnorm\n\nAnother distribution you will encounter in the course is the Beta distribution. Contary to the Normal and the Uniform distribution, there exist no universally agreed upon default parameters for the Beta distribution, and thus rbeta(1) does not work. Instead, every time you want to draw a value from the Beta distribution, you need to specify its shape, which you can do by specifying two more arguments after the number of draws. Also check out ?rbeta.\n\nrbeta(1, 1, 1)\n\n[1] 0.05367967\n\n\nHow does this Beta distribution look like? And how do the Uniform and Normal distributions look like? We can use the skills we developed thus far to figure this out. First, we can draw a large number of draws from the Beta distribution. We can then plot the density histogram of these draws to get an idea of how the distribution looks like.\n\ndraws_beta &lt;- rbeta(10000, 1, 1)\nhist(draws_beta, breaks = 50, freq = FALSE, xlab = \"x\", main = \"\")\n\n\n\n\nEven better than the empirical density that we obtained above, we can also plot the theoretical density. The dbeta function provides the density of the Beta function at any point. Thus, we can simply define the x range over which we want to plot the Beta density, then create a sequence of x points within that range and calculate the density at each of these points. This can then be plotted to get an even better understanding of how the theoretical density looks like.\n\nx &lt;- seq(0, 1, 0.01)\ndensity_beta &lt;- dbeta(x, 1, 1)\nplot(x, density_beta, type = \"l\", ylab = \"Density\")\n\n\n\n\nWith 10000 draws, the empirical density was quite close to the theoretical density. We could compare these two even better if we would plot them in the same plot. Additionally, we might ask just how many of these draws we need, and how the Beta distribution looks like for various values. Thus, we would like to do the same thing multiple times, each time only changing a small part of the code. By now, this should ring a bell: A function is needed! Below we implement a function that allows us to compare the empirical and theoretical density for various parameterisations and number of draws.\n\n#' Compares the empirical and theoretical density of a Beta distribution\n#' \n#' @param n Number of draws to take for the empirical density\n#' @param shape1 Shape parameter of Beta. See ?rbeta.\n#' @param shape2 Shape parameter of Beta. See ?rbeta.\n#' @param step_size Controls the details of the theoretical density plot.\n#' The smaller this value, the more detailed the plot. Default value is 0.01.\n#' @return Returns a plot. \n#' @examples\n#' plot_beta_density(10000, 1, 1)\n#' plot_beta_density(10000, 1, 5, step_size=1e-4)\nplot_beta_density &lt;- function(n, shape1, shape2, step_size=0.01){\n  draws_beta &lt;- rbeta(n, shape1, shape2)\n  min_x &lt;- min(draws_beta)\n  max_x &lt;- max(draws_beta)\n  x &lt;- seq(min_x, max_x, step_size)\n  density_beta &lt;- dbeta(x, shape1, shape2)\n  hist(draws_beta, \n       breaks = 50, \n       freq = FALSE,\n       xlab = \"x\", \n       ylab = \"Density\", \n       main = sprintf(\"Beta(%.2f, %.2f)\", shape1, shape2)\n       )\n  lines(x, density_beta, col=\"black\", lwd = 2)\n}\n\nEven better than above, we can see that the empirical density is very close to the theoretical density if we use 1000 draws.\n\nplot_beta_density(10000, 1, 1)\n\n\n\n\nHowever, using the function we can easily check if this is also the case if we use different parameters for the Beta and thus obtain a different shape. As shown below, changing the second shape to 4 changes the Beta distribution from a horizontal line between 0 and 1 to a a downward sloping line with the majority of the density being close to zero. The approximation of the empirical density is still good.\n\nplot_beta_density(10000, 1, 4)\n\n\n\n\nThe empiricial density becomes a worse approximation if we draw fewer values from the Beta distribution. We can easily show this by using our plot_beta_density function and simply choosing fewer values to draw from the distribution. Below we show what happens if we only draw 100 values from the distribution. Clearly, the empirical distribution is far from the theoretical.\n\nplot_beta_density(100, 1, 4)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSince distributions play an important role in probability theory and statistics, it is no surprise that many great resources exist. One of our favourite resources is the Distribution Zoo which depicts the shapes of various distributions, provides R implementation details, and gives some details on when to use which distribution.\n\n\nWe already pointed out above that if we rerun a line of code that draws a random number, we obtain a new value. A consequence of this is that every time we rerun the plot_beta_density function we obtain a slightly different plot. This can cause problems especially when the functions are more complex. For example, if we had only given you the graph and asked you to replicate the graph using your knowledge, how would you know whether your function is correct? The difference in your and our plot might be due to randomness or it might be due to a mistake in your code. This is a replicability problem.\n\nplot_beta_density(100, 1, 4)\n\n\n\n\nReplicability is an important problem in science. Only results that can be replicated should be trusted. Unfortunately, many scientific results are difficult to replicate or are just never replicated for other reasons. Nonetheless, we should always aim at making our work as replicable as possible. This is not just for others, but also for ourselves. Sometimes we need to obtain the same graph again because we migth have to change the title. If the function provides a new graph each time, it becomes difficult to convince anyone that we actually used the same graph as before. Thus, we have to make our code replicable. Clean code is a first step towards that, but if we use randomness, we also need to use a seed.\nA seed assures that each time we run the code, we will obtain exactly the same results. The emphsise is on run the same code. We only obtain the same result if we run everything after the line at which we set the seed. To set a seed, we use set.seed and provide any integer to it. A good practice is to use a large integer, but even set.seed(1) is better than not setting any seed.\n\nset.seed(6150533)\nrgamma(1, 1)\n\n[1] 1.583487\n\n\nNow that the seed is set, we can run the same code as above and obtain the exact same result as before.\n\nset.seed(6150533)\nrgamma(1, 1)\n\n[1] 1.583487\n\n\nWe cannot emphasise enough that you should always set a seed. Not setting a seed will lead to problems later on and in this course will lead to potential loss of points."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Short Introduction to R for Probability",
    "section": "",
    "text": "Preface\n\n\n\n\n\n\nEBC1024 - Probability Theory\n\n\n\nThe current notes are part of EBC1024 - Probability Theory at Maastricht University. For all course related content, please check the syllabus and the Canvas page. Information relating to Econometrics and Operations Research can be found on the official website.\n\n\nProbability theory is an integral part of your Econometrics and Operations Research education. Many problems you will encounter in other courses and in your future careers will rely on basic and sometimes more advanced probability concepts. We will, therefore, introduce you to the basics of probability theory in EBC1024. In the past, we focused on theory and applications that can be solved by hand. However, many modern problems cannot be solved by hand, and instead, they are solved via simulations. Additionally, probability can sometimes be dry and difficult to intuitively understand. For those two reasons, we decided to change things this year. Instead of only focusing on problems that can be solved by hand, we will also introduce computational methods. This, however, requires some basic knowledge in programming. The current notes will, therefore, introduce computational methods using the R programming language.\nMany other introductions to R have been written, most of them much more extensive than the current notes. We list a few of them below. We encourage everyone to check them out.\n\nAn Introduction to R\nR for Data Science\nHands-On Programming with R"
  }
]